{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense,Flatten,Activation,Dropout,Input,Subtract,add,maximum,minimum\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import skimage\n",
    "import time\n",
    "from skimage.color import rgb2gray\n",
    "%matplotlib inline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img_path):\n",
    "    # extract pre-trained face detector\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "    # load color (BGR) image\n",
    "    img = cv2.imread(img_path)\n",
    "    # convert BGR image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # find faces in image\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    cropped = img\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped = img[y:y+h,x:x+w]\n",
    "        cropped = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './lfw-deepfunneled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS \n",
    "BATCHES_IN_A_EPOCH = 20\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 150\n",
    "LR = 0.001   # LEARNING RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "input_shape = (IMAGE_SIZE,IMAGE_SIZE,1)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(2,2),padding = 'same',input_shape=(IMAGE_SIZE,IMAGE_SIZE,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(3,3))\n",
    "model.add(Conv2D(64,(2,2),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(3,3))\n",
    "model.add(Conv2D(128,(2,2),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(3,3))\n",
    "model.add(Conv2D(256,(2,2),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(3,3))\n",
    "# model.add(Conv2D(512,(2,2),padding = 'same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(3,3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='sigmoid'))\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "maxi = maximum([encoded_l,encoded_r])\n",
    "mini = minimum([encoded_l,encoded_r])\n",
    "\n",
    "subtracted = Subtract()([maxi,mini])\n",
    "\n",
    "fc1 = Dense(1024,activation='relu')(subtracted)\n",
    "out = Dense(1,activation='sigmoid')(fc1)\n",
    "\n",
    "NetWork = Model(input=[left_input,right_input],outputs = out)\n",
    "NetWork.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NetWork.compile(optimizer=Adam(lr=LR),loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple= []   # LIST STORING THE NAMES OF THE PERSON CONTAINING MULTIPLE IMAGES\n",
    "count = 0   # STORES THE COUNT OF TOTAL IMAGES FOR THE PERSON HAVING MULTIPLE IMAGES\n",
    "classes = 0\n",
    "for name in os.listdir(data_dir):\n",
    "    classes+=1\n",
    "    images= []\n",
    "    images = os.listdir(data_dir+'/'+name)\n",
    "    if(len(images)>1):\n",
    "        count+=len(images)\n",
    "        multiple.append(name)\n",
    "\n",
    "print(f\"Total no of persons: {classes}\")\n",
    "print(\"Total no of people having multiple images: {} \".format(len(multiple)))\n",
    "print(f\"Total count of images of such person is: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_pairs(batch_size):\n",
    "#     print(\"GETTING MATCHING PAIRS\")\n",
    "    l_image=[]\n",
    "    r_image=[]\n",
    "    for i in range(0,batch_size):\n",
    "        num = random.randint(0,len(multiple)-1)\n",
    "        name = multiple[num]\n",
    "        total = []\n",
    "        total = os.listdir('./lfw-deepfunneled/'+name)\n",
    "        img1 = random.randint(0,len(total)-1)\n",
    "        img2 = random.randint(0,len(total)-1)\n",
    "        if(img1==img2):\n",
    "            img2 = (img1+1)%(len(total))\n",
    "        \n",
    "        img1_path = './lfw-deepfunneled/'+name+'/'+total[img1]\n",
    "        img2_path = './lfw-deepfunneled/'+name+'/'+total[img2]\n",
    "        l_img = crop_image(img1_path)\n",
    "        r_img = crop_image(img2_path)\n",
    "        l_img = (rgb2gray(l_img))\n",
    "        r_img = (rgb2gray(r_img))\n",
    "        l_img = skimage.transform.resize(l_img, (IMAGE_SIZE,IMAGE_SIZE,1))\n",
    "        r_img = skimage.transform.resize(r_img, (IMAGE_SIZE,IMAGE_SIZE,1))\n",
    "        l_img = np.asarray(l_img)\n",
    "        r_img = np.asarray(r_img)\n",
    "        \n",
    "        l_image.append(l_img)\n",
    "        r_image.append(r_img)\n",
    "\n",
    "\n",
    "    l_image = np.asarray(l_image)\n",
    "    r_image = np.asarray(r_image)\n",
    "    return l_image,r_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_matching_pairs(batch_size):\n",
    "#     print(\"GETTING NON MATCHING PAIRS...\")\n",
    "    l_image=[]\n",
    "    r_image=[]\n",
    "    for i in range(0,batch_size):\n",
    "        num1 = random.randint(0,len(multiple)-1)\n",
    "        num2 = random.randint(0,len(multiple)-1)\n",
    "        if(num1==num2):\n",
    "            num2 = (num1+1)%(len(multiple))\n",
    "        name1 = multiple[num1]\n",
    "        name2 = multiple[num2]\n",
    "        total1 = []\n",
    "        total2 = []\n",
    "        total1 = os.listdir('./lfw-deepfunneled/'+name1)\n",
    "        total2 = os.listdir('./lfw-deepfunneled/'+name2)\n",
    "        img1 = random.randint(0,len(total1)-1)\n",
    "        img2 = random.randint(0,len(total2)-1)\n",
    "        img1_path = './lfw-deepfunneled/'+name1+'/'+total1[img1]\n",
    "        img2_path = './lfw-deepfunneled/'+name2+'/'+total2[img2]\n",
    "        l_img = crop_image(img1_path)\n",
    "        r_img = crop_image(img2_path)\n",
    "        l_img = (rgb2gray(l_img))\n",
    "        r_img = (rgb2gray(r_img))\n",
    "\n",
    "        l_img = skimage.transform.resize(l_img, (IMAGE_SIZE,IMAGE_SIZE,1))\n",
    "        r_img = skimage.transform.resize(r_img, (IMAGE_SIZE,IMAGE_SIZE,1))\n",
    "        l_img = np.asarray(l_img)\n",
    "        r_img = np.asarray(r_img)\n",
    "\n",
    "        l_image.append(l_img)\n",
    "        r_image.append(r_img)\n",
    "\n",
    "\n",
    "    l_image = np.asarray(l_image)\n",
    "    r_image = np.asarray(r_image)\n",
    "    return l_image,r_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "losses = []\n",
    "def train(epochs=20):\n",
    "    print(\"Training Begins...\")\n",
    "    for epoch in range(1,epochs+1):\n",
    "        loss = 0\n",
    "        start_time = time.time()\n",
    "        for j in range(0,BATCHES_IN_A_EPOCH//4):\n",
    "            l,r = get_non_matching_pairs(BATCH_SIZE)      # non-matching pairs\n",
    "            target = np.ones(BATCH_SIZE)                  # 1s\n",
    "            non_matching_loss1 = NetWork.train_on_batch([l,r],target)\n",
    "            \n",
    "            l,r = get_matching_pairs(BATCH_SIZE)          # matching pairs\n",
    "            target = np.zeros(BATCH_SIZE)                 # 0s\n",
    "            matching_loss1 = NetWork.train_on_batch([l,r],target)\n",
    "            \n",
    "            l,r = get_non_matching_pairs(BATCH_SIZE)      # non-matching pairs\n",
    "            target = np.ones(BATCH_SIZE)                  # 1s\n",
    "            non_matching_loss2 = NetWork.train_on_batch([l,r],target)\n",
    "            \n",
    "            l,r = get_matching_pairs(BATCH_SIZE)          # matching pairs\n",
    "            target = np.zeros(BATCH_SIZE)                 # 0s\n",
    "            matching_loss2 = NetWork.train_on_batch([l,r],target)\n",
    "            \n",
    "            loss = matching_loss1+matching_loss2+non_matching_loss1+non_matching_loss2\n",
    "\n",
    "        losses.append(loss)\n",
    "        print(f\"Epoch {epoch}/{epochs}:\\nDuration:{time.time()-start_time}\\nTraining_loss = {np.mean(loss):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_non_matching_pairs():\n",
    "    l_image=[]\n",
    "    r_image=[]\n",
    "    done=[]\n",
    "    img1=[]\n",
    "    img2=[]\n",
    "    for name1 in os.listdir('./TestFaces'):\n",
    "        done.append(name1)\n",
    "        img1 = os.listdir('./TestFaces/'+name1)\n",
    "        for name2 in os.listdir('./TestFaces'):\n",
    "            if name2 in done:\n",
    "                continue\n",
    "            img2 = os.listdir('./TestFaces/'+name2)\n",
    "            for i in range(0,3):\n",
    "                img1_path = './TestFaces/'+name1+'/'+img1[i]\n",
    "                img2_path = './TestFaces/'+name2+'/'+img2[i]\n",
    "                l_img = crop_image(img1_path)\n",
    "                r_img = crop_image(img2_path)\n",
    "                l_img = (rgb2gray(l_img))\n",
    "                r_img = (rgb2gray(r_img))\n",
    "                \n",
    "                plt.subplot(1,3,1)\n",
    "                plt.imshow(l_img, cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n",
    "                plt.subplot(1,3,3)\n",
    "                plt.imshow(r_img, cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n",
    "                plt.show()\n",
    "\n",
    "                l_img = skimage.transform.resize(l_img, (IMAGE_SIZE,IMAGE_SIZE,1))\n",
    "                r_img = skimage.transform.resize(r_img, (IMAGE_SIZE,IMAGE_SIZE,1))\n",
    "                l_img = np.asarray(l_img)\n",
    "                r_img = np.asarray(r_img)\n",
    "                l_image.append(l_img)\n",
    "                r_image.append(r_img)\n",
    "\n",
    "\n",
    "    l_image = np.asarray(l_image)\n",
    "    r_image = np.asarray(r_image)\n",
    "    return l_image,r_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l,r = test_non_matching_pairs()\n",
    "print(l.shape)\n",
    "print(r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = NetWork.predict([l,r])\n",
    "acc=0\n",
    "for num in test_result:\n",
    "    if(num>=THRESHOLD):\n",
    "        acc+=1\n",
    "print(f'ACCURACY: {(acc/l.shape[0])*100:.3f}%')\n",
    "print(\"\\n\\n\")\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_matching_pairs():\n",
    "    l_image=[]\n",
    "    r_image=[]\n",
    "    for names in os.listdir('./TestFaces'):\n",
    "        print(\"NAME: \"+names)\n",
    "        for i in range(0,3):\n",
    "            img1_path = './TestFaces/'+names+'/'+str((i%3)+1)+'.jpg'\n",
    "            img2_path = './TestFaces/'+names+'/'+str(((i+1)%3)+1)+'.jpg'\n",
    "            l_img = crop_image(img1_path)\n",
    "            r_img = crop_image(img2_path)\n",
    "            l_img = (rgb2gray(l_img))\n",
    "            r_img = (rgb2gray(r_img))\n",
    "    \n",
    "            print(\"Images: \"+str((i%3)+1)+\"\\t\\t\\t\\t\"+str(((i+1)%3)+1))\n",
    "            plt.subplot(1,3,1)\n",
    "            plt.imshow(l_img, cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n",
    "            plt.subplot(1,3,3)\n",
    "            plt.imshow(r_img, cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n",
    "            plt.show()\n",
    "            \n",
    "            l_img = skimage.transform.resize(l_img, (IMAGE_SIZE,IMAGE_SIZE,1))\n",
    "            r_img = skimage.transform.resize(r_img, (IMAGE_SIZE,IMAGE_SIZE,1))\n",
    "            l_img = np.asarray(l_img)\n",
    "            r_img = np.asarray(r_img)\n",
    "            l_image.append(l_img)\n",
    "            r_image.append(r_img)\n",
    "    l_image = np.asarray(l_image)\n",
    "    r_image = np.asarray(r_image)\n",
    "    return l_image,r_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l,r = test_matching_pairs()\n",
    "print(l.shape)\n",
    "print(r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = NetWork.predict([l,r])\n",
    "acc=0\n",
    "for num in test_result:\n",
    "    if(num<THRESHOLD):\n",
    "        acc+=1\n",
    "print(f'ACCURACY: {(acc/l.shape[0])*100:.3f}%')\n",
    "print(\"\\n\\n\")\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./try4(BEST)')\n",
    "from keras.models import model_from_json\n",
    "model_json = NetWork.to_json()\n",
    "with open(\"model4d.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "NetWork.save_weights(\"model4d.h5\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('try4(BEST)/model4d.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"try4(BEST)/model4d.h5\")\n",
    "print(\"Model Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll=[]\n",
    "l_img = crop_image('./FACES/img.jpeg')\n",
    "l_img = (rgb2gray(l_img))\n",
    "plt.imshow(l_img, cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n",
    "l_img = skimage.transform.resize(l_img, (IMAGE_SIZE,IMAGE_SIZE,1))\n",
    "l_img = np.asarray(l_img)\n",
    "ll.append(l_img)\n",
    "ll = np.asarray(ll)\n",
    "ll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rr=[]\n",
    "r_img = crop_image('./FACES/PIC2.jpg')\n",
    "r_img = (rgb2gray(r_img))\n",
    "plt.imshow(r_img, cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n",
    "r_img = skimage.transform.resize(r_img, (IMAGE_SIZE,IMAGE_SIZE,1))\n",
    "r_img = np.asarray(r_img)\n",
    "rr.append(r_img)\n",
    "rr = np.asarray(rr)\n",
    "rr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict([ll,rr])             # close to zero means same person"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
